{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403ed055",
   "metadata": {},
   "source": [
    "# NOAA Weather Station Data Tool\n",
    "\n",
    "This notebook retrieves information about all NOAA weather stations including their geographical information (latitude, longitude, elevation, etc.) and saves the data to a DataFrame. It can also fetch historical weather data for these stations.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tool is designed to:\n",
    "1. Fetch all NOAA weather stations with geographical data\n",
    "2. Retrieve historical weather data for these stations\n",
    "3. Create pandas DataFrames that can be converted to temp tables in Databricks\n",
    "\n",
    "## Features\n",
    "\n",
    "* Retrieves metadata for all NOAA weather stations\n",
    "* Gets historical weather data for stations (temperature, precipitation, snow, wind)\n",
    "* Exports data to CSV files for analysis\n",
    "* Handles NOAA API pagination and rate limits\n",
    "* Easily configurable via parameters at the top of the notebook\n",
    "\n",
    "## Requirements\n",
    "\n",
    "* Python 3.6+\n",
    "* pandas\n",
    "* requests\n",
    "\n",
    "Install required packages with:\n",
    "```\n",
    "pip install pandas requests\n",
    "```\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "1. You need a NOAA API token. Register at: https://www.ncdc.noaa.gov/cdo-web/token\n",
    "2. Enter your token in the configuration section below\n",
    "3. Adjust other parameters as needed\n",
    "4. Run the notebook cells sequentially\n",
    "\n",
    "For Databricks, copy the entire notebook to your Databricks workspace and use the temp table creation cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbc6969",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "First, we'll import the necessary libraries and set up configuration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cb1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Configuration parameters - modify these as needed\n",
    "# =================================================\n",
    "\n",
    "# Your NOAA API token - replace with your actual token\n",
    "NOAA_API_TOKEN = \"YOUR_NOAA_API_TOKEN_HERE\"\n",
    "\n",
    "# Historical data parameters\n",
    "GET_HISTORICAL_DATA = True  # Set to False to only get station information\n",
    "DAYS_OF_HISTORICAL_DATA = 90  # Number of days of historical data to fetch\n",
    "MAX_STATIONS = 100  # Maximum number of stations to get historical data for (0 for all)\n",
    "\n",
    "# Data types to retrieve\n",
    "# TMAX: Maximum temperature\n",
    "# TMIN: Minimum temperature\n",
    "# PRCP: Precipitation\n",
    "# SNOW: Snowfall\n",
    "# AWND: Average daily wind speed\n",
    "DATA_TYPES = \"TMAX,TMIN,PRCP,SNOW,AWND\"\n",
    "\n",
    "# API parameters\n",
    "API_LIMIT = 1000  # Number of results per API request\n",
    "API_RATE_LIMIT_DELAY = 0.2  # Seconds to wait between API calls (NOAA limits to 5 requests/sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11fac4",
   "metadata": {},
   "source": [
    "## NOAA Data Fetcher Class\n",
    "\n",
    "Now we'll create a class to handle fetching data from the NOAA API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbca787",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoaaDataFetcher:\n",
    "    \"\"\"Class to fetch NOAA station and historical weather data.\"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://www.ncdc.noaa.gov/cdo-web/api/v2\"\n",
    "    \n",
    "    def __init__(self, token):\n",
    "        \"\"\"Initialize with an API token.\"\"\"\n",
    "        self.token = token\n",
    "        if not self.token:\n",
    "            raise ValueError(\"NOAA API token is required.\")\n",
    "        self.headers = {\"token\": self.token}\n",
    "    \n",
    "    def get_stations(self, limit=1000, offset=1):\n",
    "        \"\"\"\n",
    "        Fetch weather stations data from NOAA API.\n",
    "        \n",
    "        Args:\n",
    "            limit: Number of stations to retrieve per request\n",
    "            offset: Starting offset for pagination\n",
    "            \n",
    "        Returns:\n",
    "            List of station data dictionaries\n",
    "        \"\"\"\n",
    "        stations = []\n",
    "        url = f\"{self.BASE_URL}/stations\"\n",
    "        \n",
    "        while True:\n",
    "            params = {\n",
    "                \"limit\": limit,\n",
    "                \"offset\": offset,\n",
    "                # Include stations with data in GHCND dataset\n",
    "                \"datasetid\": \"GHCND\",\n",
    "                # Sort by station ID\n",
    "                \"sortfield\": \"id\"\n",
    "            }\n",
    "            \n",
    "            print(f\"Fetching stations {offset} to {offset + limit - 1}...\")\n",
    "            response = requests.get(url, headers=self.headers, params=params)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                print(f\"Error retrieving stations: {response.status_code}\")\n",
    "                print(response.text)\n",
    "                break\n",
    "                \n",
    "            data = response.json()\n",
    "            if \"results\" not in data or not data[\"results\"]:\n",
    "                break\n",
    "                \n",
    "            stations.extend(data[\"results\"])\n",
    "            print(f\"Retrieved {len(data['results'])} stations\")\n",
    "            \n",
    "            # If we've received fewer results than the limit, we've reached the end\n",
    "            if len(data[\"results\"]) < limit:\n",
    "                break\n",
    "                \n",
    "            offset += limit\n",
    "            # Respect NOAA API rate limits\n",
    "            time.sleep(API_RATE_LIMIT_DELAY)\n",
    "        \n",
    "        print(f\"Total stations retrieved: {len(stations)}\")\n",
    "        return stations\n",
    "\n",
    "    def get_historical_data(self, station_id, start_date, end_date, datatype):\n",
    "        \"\"\"\n",
    "        Fetch historical weather data for a specific station.\n",
    "        \n",
    "        Args:\n",
    "            station_id: NOAA station identifier\n",
    "            start_date: Start date in YYYY-MM-DD format\n",
    "            end_date: End date in YYYY-MM-DD format\n",
    "            datatype: Comma-separated list of data types to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with historical weather data or None if error\n",
    "        \"\"\"\n",
    "        url = f\"{self.BASE_URL}/data\"\n",
    "        params = {\n",
    "            \"datasetid\": \"GHCND\",  # Global Historical Climatology Network Daily\n",
    "            \"stationid\": station_id,\n",
    "            \"startdate\": start_date,\n",
    "            \"enddate\": end_date,\n",
    "            \"datatypeid\": datatype,\n",
    "            \"limit\": 1000,\n",
    "            \"units\": \"standard\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers, params=params)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                print(f\"Error retrieving data for station {station_id}: {response.status_code}\")\n",
    "                return None\n",
    "                \n",
    "            data = response.json()\n",
    "            if \"results\" not in data or not data[\"results\"]:\n",
    "                print(f\"No data available for station {station_id}\")\n",
    "                return None\n",
    "                \n",
    "            # Convert to DataFrame\n",
    "            df = pd.json_normalize(data[\"results\"])\n",
    "            # Add station ID as a column\n",
    "            df[\"station_id\"] = station_id\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing data for station {station_id}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def process_stations_to_df(self, stations):\n",
    "        \"\"\"\n",
    "        Convert stations list to a pandas DataFrame with clean columns.\n",
    "        \n",
    "        Args:\n",
    "            stations: List of station dictionaries from the API\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with station information\n",
    "        \"\"\"\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(stations)\n",
    "        \n",
    "        # Handle nested location data\n",
    "        if 'elevation' in df.columns:\n",
    "            df['elevation_meters'] = df['elevation']\n",
    "        \n",
    "        if 'location' in df.columns:\n",
    "            # Extract latitude and longitude from the location dictionary\n",
    "            df['latitude'] = df['location'].apply(lambda x: x.get('latitude') if isinstance(x, dict) else None)\n",
    "            df['longitude'] = df['location'].apply(lambda x: x.get('longitude') if isinstance(x, dict) else None)\n",
    "            df.drop('location', axis=1, inplace=True)\n",
    "        \n",
    "        # Convert dates to datetime\n",
    "        for date_col in ['mindate', 'maxdate']:\n",
    "            if date_col in df.columns:\n",
    "                df[date_col] = pd.to_datetime(df[date_col])\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58376b34",
   "metadata": {},
   "source": [
    "## Fetch Station Data\n",
    "\n",
    "Now we'll use the NoaaDataFetcher class to retrieve data for all NOAA weather stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee8a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize fetcher with configured token\n",
    "fetcher = NoaaDataFetcher(token=NOAA_API_TOKEN)\n",
    "\n",
    "# Get all stations\n",
    "stations = fetcher.get_stations(limit=API_LIMIT)\n",
    "\n",
    "# Convert to DataFrame\n",
    "stations_df = fetcher.process_stations_to_df(stations)\n",
    "\n",
    "# Display the first few rows of the stations DataFrame\n",
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e0737f",
   "metadata": {},
   "source": [
    "## Station Data Overview\n",
    "\n",
    "Let's explore the station data to understand what information we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ff87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display DataFrame info\n",
    "print(\"DataFrame Information:\")\n",
    "print(f\"Number of stations: {len(stations_df)}\")\n",
    "print(\"\\nColumns:\")\n",
    "for col in stations_df.columns:\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "# Show basic statistics for numerical columns\n",
    "print(\"\\nBasic Statistics:\")\n",
    "stations_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97461bd",
   "metadata": {},
   "source": [
    "## Fetch Historical Weather Data\n",
    "\n",
    "Now we'll fetch historical weather data for the stations. This can be time-consuming for a large number of stations, so we can limit the number of stations to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf6dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell if GET_HISTORICAL_DATA is True\n",
    "if GET_HISTORICAL_DATA:\n",
    "    # Calculate date range\n",
    "    end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    start_date = (datetime.now() - timedelta(days=DAYS_OF_HISTORICAL_DATA)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    all_historical_data = []\n",
    "    \n",
    "    # Limit number of stations if specified\n",
    "    station_ids = stations_df['id'].tolist()\n",
    "    if MAX_STATIONS > 0:\n",
    "        station_ids = station_ids[:MAX_STATIONS]\n",
    "    \n",
    "    print(f\"Fetching historical data for {len(station_ids)} stations...\")\n",
    "    print(f\"Date range: {start_date} to {end_date}\")\n",
    "    \n",
    "    for i, station_id in enumerate(station_ids):\n",
    "        print(f\"Processing station {i+1}/{len(station_ids)}: {station_id}\")\n",
    "        hist_data = fetcher.get_historical_data(station_id, start_date, end_date, DATA_TYPES)\n",
    "        \n",
    "        if hist_data is not None:\n",
    "            all_historical_data.append(hist_data)\n",
    "        \n",
    "        # Respect NOAA API rate limits\n",
    "        time.sleep(API_RATE_LIMIT_DELAY)\n",
    "    \n",
    "    if all_historical_data:\n",
    "        # Combine all historical data\n",
    "        historical_df = pd.concat(all_historical_data, ignore_index=True)\n",
    "        print(f\"Retrieved historical data: {len(historical_df)} records from {len(station_ids)} stations\")\n",
    "        \n",
    "        # Display the first few rows\n",
    "        historical_df.head()\n",
    "    else:\n",
    "        print(\"No historical data was retrieved.\")\n",
    "else:\n",
    "    print(\"Historical data retrieval is disabled. Set GET_HISTORICAL_DATA = True to enable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0df220",
   "metadata": {},
   "source": [
    "## Historical Data Overview\n",
    "\n",
    "If we've retrieved historical data, let's explore it to understand the structure and contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb39839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell if GET_HISTORICAL_DATA is True and we have historical data\n",
    "if GET_HISTORICAL_DATA and 'historical_df' in locals() and len(historical_df) > 0:\n",
    "    # Display DataFrame info\n",
    "    print(\"Historical DataFrame Information:\")\n",
    "    print(f\"Number of records: {len(historical_df)}\")\n",
    "    print(\"\\nColumns:\")\n",
    "    for col in historical_df.columns:\n",
    "        print(f\"- {col}\")\n",
    "    \n",
    "    # Show basic statistics\n",
    "    print(\"\\nBasic Statistics:\")\n",
    "    historical_df.describe()\n",
    "    \n",
    "    # Distribution by data type\n",
    "    print(\"\\nDistribution by Data Type:\")\n",
    "    print(historical_df['datatype'].value_counts())\n",
    "    \n",
    "    # Distribution by station\n",
    "    print(\"\\nTop 10 Stations by Record Count:\")\n",
    "    print(historical_df['station_id'].value_counts().head(10))\n",
    "else:\n",
    "    print(\"No historical data available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ba06c8",
   "metadata": {},
   "source": [
    "## Prepare Data for Databricks\n",
    "\n",
    "Now we'll prepare the data to be easily converted to temporary tables in Databricks. This includes ensuring proper data types and organizing the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0673a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare station data for Databricks\n",
    "def prepare_stations_for_databricks(df):\n",
    "    \"\"\"Prepare station DataFrame for use in Databricks.\"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_prep = df.copy()\n",
    "    \n",
    "    # Ensure proper data types\n",
    "    if 'latitude' in df_prep.columns:\n",
    "        df_prep['latitude'] = pd.to_numeric(df_prep['latitude'], errors='coerce')\n",
    "    if 'longitude' in df_prep.columns:\n",
    "        df_prep['longitude'] = pd.to_numeric(df_prep['longitude'], errors='coerce')\n",
    "    if 'elevation_meters' in df_prep.columns:\n",
    "        df_prep['elevation_meters'] = pd.to_numeric(df_prep['elevation_meters'], errors='coerce')\n",
    "    \n",
    "    # Add data collection timestamp\n",
    "    df_prep['data_collection_ts'] = datetime.now()\n",
    "    \n",
    "    return df_prep\n",
    "\n",
    "# Function to prepare historical data for Databricks\n",
    "def prepare_historical_for_databricks(df):\n",
    "    \"\"\"Prepare historical DataFrame for use in Databricks.\"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_prep = df.copy()\n",
    "    \n",
    "    # Convert values to appropriate numeric types\n",
    "    if 'value' in df_prep.columns:\n",
    "        df_prep['value'] = pd.to_numeric(df_prep['value'], errors='coerce')\n",
    "    \n",
    "    # Ensure date is in proper datetime format\n",
    "    if 'date' in df_prep.columns:\n",
    "        df_prep['date'] = pd.to_datetime(df_prep['date'], errors='coerce')\n",
    "    \n",
    "    # Add data collection timestamp\n",
    "    df_prep['data_collection_ts'] = datetime.now()\n",
    "    \n",
    "    return df_prep\n",
    "\n",
    "# Prepare the station data\n",
    "stations_db_df = prepare_stations_for_databricks(stations_df)\n",
    "print(f\"Prepared stations DataFrame for Databricks: {len(stations_db_df)} rows\")\n",
    "\n",
    "# Prepare historical data if available\n",
    "if GET_HISTORICAL_DATA and 'historical_df' in locals() and len(historical_df) > 0:\n",
    "    historical_db_df = prepare_historical_for_databricks(historical_df)\n",
    "    print(f\"Prepared historical DataFrame for Databricks: {len(historical_db_df)} rows\")\n",
    "else:\n",
    "    print(\"No historical data to prepare for Databricks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc1dbf1",
   "metadata": {},
   "source": [
    "## Create Temp Tables in Databricks\n",
    "\n",
    "When you copy this notebook to Databricks, you can use the following code to create temporary tables from the DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2124cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Databricks, uncomment and run this code:\n",
    "\n",
    "# Create temp table from stations DataFrame\n",
    "# stations_db_df.createOrReplaceTempView(\"noaa_stations\")\n",
    "# display(spark.sql(\"SELECT * FROM noaa_stations LIMIT 10\"))\n",
    "\n",
    "# Create temp table from historical DataFrame if available\n",
    "# if 'historical_db_df' in locals() and historical_db_df is not None:\n",
    "#     historical_db_df.createOrReplaceTempView(\"noaa_historical_data\")\n",
    "#     display(spark.sql(\"SELECT * FROM noaa_historical_data LIMIT 10\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937fae76",
   "metadata": {},
   "source": [
    "## Example Queries for Analysis\n",
    "\n",
    "Here are some example queries you can run in Databricks to analyze the NOAA weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7025fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Databricks, you can run SQL queries like these:\n",
    "\n",
    "# 1. Find stations with the highest elevation\n",
    "# display(spark.sql(\"\"\"\n",
    "#     SELECT id, name, latitude, longitude, elevation_meters\n",
    "#     FROM noaa_stations\n",
    "#     WHERE elevation_meters IS NOT NULL\n",
    "#     ORDER BY elevation_meters DESC\n",
    "#     LIMIT 20\n",
    "# \"\"\"))\n",
    "\n",
    "# 2. Get average temperatures by station\n",
    "# display(spark.sql(\"\"\"\n",
    "#     SELECT \n",
    "#         s.id, \n",
    "#         s.name,\n",
    "#         s.latitude,\n",
    "#         s.longitude,\n",
    "#         AVG(CASE WHEN h.datatype = 'TMAX' THEN h.value / 10 END) as avg_max_temp_celsius,\n",
    "#         AVG(CASE WHEN h.datatype = 'TMIN' THEN h.value / 10 END) as avg_min_temp_celsius\n",
    "#     FROM noaa_stations s\n",
    "#     JOIN noaa_historical_data h ON s.id = h.station_id\n",
    "#     WHERE h.datatype IN ('TMAX', 'TMIN')\n",
    "#     GROUP BY s.id, s.name, s.latitude, s.longitude\n",
    "#     HAVING avg_max_temp_celsius IS NOT NULL\n",
    "#     ORDER BY avg_max_temp_celsius DESC\n",
    "#     LIMIT 20\n",
    "# \"\"\"))\n",
    "\n",
    "# 3. Analyze precipitation patterns\n",
    "# display(spark.sql(\"\"\"\n",
    "#     SELECT \n",
    "#         h.date,\n",
    "#         COUNT(DISTINCT h.station_id) as station_count,\n",
    "#         AVG(CASE WHEN h.datatype = 'PRCP' THEN h.value / 10 END) as avg_precipitation_mm\n",
    "#     FROM noaa_historical_data h\n",
    "#     WHERE h.datatype = 'PRCP'\n",
    "#     GROUP BY h.date\n",
    "#     ORDER BY h.date\n",
    "# \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bfc1f6",
   "metadata": {},
   "source": [
    "## Saving Data For Further Use\n",
    "\n",
    "If you need to save the data for use outside of Databricks, you can export it to various formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV files locally\n",
    "# Not needed in Databricks but useful for local analysis\n",
    "stations_df.to_csv(\"noaa_stations.csv\", index=False)\n",
    "print(f\"Saved {len(stations_df)} stations to noaa_stations.csv\")\n",
    "\n",
    "if GET_HISTORICAL_DATA and 'historical_df' in locals() and len(historical_df) > 0:\n",
    "    historical_df.to_csv(\"noaa_historical_data.csv\", index=False)\n",
    "    print(f\"Saved historical data to noaa_historical_data.csv\")\n",
    "    \n",
    "# In Databricks, you might want to save to Delta tables instead:\n",
    "# stations_db_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"noaa_stations\")\n",
    "# if 'historical_db_df' in locals() and historical_db_df is not None:\n",
    "#     historical_db_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"noaa_historical_data\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
